{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-08-09T10:43:24.557656Z",
     "iopub.status.busy": "2025-08-09T10:43:24.556917Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T10:49:23.026465Z",
     "iopub.status.busy": "2025-08-09T10:49:23.026228Z",
     "iopub.status.idle": "2025-08-09T10:49:23.043250Z",
     "shell.execute_reply": "2025-08-09T10:49:23.042728Z",
     "shell.execute_reply.started": "2025-08-09T10:49:23.026437Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import zipfile\n",
    "import requests\n",
    "import glob as glob\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import logging\n",
    "import absl\n",
    "\n",
    "# Filter absl warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"absl\")\n",
    "\n",
    "# Capture all warnings in the logging system\n",
    "logging.captureWarnings(True)\n",
    "\n",
    "# Set the absl logger level to 'error' to suppress warnings\n",
    "absl_logger = logging.getLogger(\"absl\")\n",
    "absl_logger.setLevel(logging.ERROR)\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-08-09T10:49:35.066483Z",
     "iopub.status.busy": "2025-08-09T10:49:35.065804Z",
     "iopub.status.idle": "2025-08-09T10:49:35.073806Z",
     "shell.execute_reply": "2025-08-09T10:49:35.073124Z",
     "shell.execute_reply.started": "2025-08-09T10:49:35.066460Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir('/kaggle/input/coco-2017-dataset/coco2017/val2017'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T10:49:43.426432Z",
     "iopub.status.busy": "2025-08-09T10:49:43.425794Z",
     "iopub.status.idle": "2025-08-09T10:49:45.109969Z",
     "shell.execute_reply": "2025-08-09T10:49:45.109266Z",
     "shell.execute_reply.started": "2025-08-09T10:49:43.426408Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images found: 5000\n",
      "Example image path: /kaggle/input/coco-2017-dataset/coco2017/val2017/000000011197.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Path to test set\n",
    "test_path = '/kaggle/input/coco-2017-dataset/coco2017/val2017'\n",
    "images = glob.glob(os.path.join(test_path, '**', '*.*'), recursive=True)\n",
    "valid_exts = {'.jpg', '.jpeg', '.png'}\n",
    "images = [img for img in images if os.path.splitext(img)[1].lower() in valid_exts]\n",
    "print(f\"Total images found: {len(images)}\")\n",
    "if images:\n",
    "    print(f\"Example image path: {images[0]}\")\n",
    "else:\n",
    "    print(\"No images found. Check your dataset path or extensions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T10:49:49.398721Z",
     "iopub.status.busy": "2025-08-09T10:49:49.398251Z",
     "iopub.status.idle": "2025-08-09T10:49:49.403049Z",
     "shell.execute_reply": "2025-08-09T10:49:49.402227Z",
     "shell.execute_reply.started": "2025-08-09T10:49:49.398690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    image=cv2.imread(path)\n",
    "    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    image=np.expand_dims(image,axis=0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T10:49:52.592603Z",
     "iopub.status.busy": "2025-08-09T10:49:52.591850Z",
     "iopub.status.idle": "2025-08-09T10:49:53.492975Z",
     "shell.execute_reply": "2025-08-09T10:49:53.491561Z",
     "shell.execute_reply.started": "2025-08-09T10:49:52.592575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "sample_images=random.sample(images,5)\n",
    "\n",
    "fig,ax =plt.subplots(nrows=2,ncols=2,figsize=(20,14))\n",
    "for axis,image_path in zip(ax.flat,sample_images):\n",
    "    image=load_image(image_path)\n",
    "    axis.imshow(image[0])\n",
    "    axis.axis('off')\n",
    "    axis.set_title(os.path.basename(image_path))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T10:50:07.224332Z",
     "iopub.status.busy": "2025-08-09T10:50:07.223635Z",
     "iopub.status.idle": "2025-08-09T10:50:07.231116Z",
     "shell.execute_reply": "2025-08-09T10:50:07.230306Z",
     "shell.execute_reply.started": "2025-08-09T10:50:07.224290Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class_index =  \\\n",
    "{\n",
    "         1: 'person',\n",
    "         2: 'bicycle',\n",
    "         3: 'car',\n",
    "         4: 'motorcycle',\n",
    "         5: 'airplane',\n",
    "         6: 'bus',\n",
    "         7: 'train',\n",
    "         8: 'truck',\n",
    "         9: 'boat',\n",
    "         10: 'traffic light',\n",
    "         11: 'fire hydrant',\n",
    "         13: 'stop sign',\n",
    "         14: 'parking meter',\n",
    "         15: 'bench',\n",
    "         16: 'bird',\n",
    "         17: 'cat',\n",
    "         18: 'dog',\n",
    "         19: 'horse',\n",
    "         20: 'sheep',\n",
    "         21: 'cow',\n",
    "         22: 'elephant',\n",
    "         23: 'bear',\n",
    "         24: 'zebra',\n",
    "         25: 'giraffe',\n",
    "         27: 'backpack',\n",
    "         28: 'umbrella',\n",
    "         31: 'handbag',\n",
    "         32: 'tie',\n",
    "         33: 'suitcase',\n",
    "         34: 'frisbee',\n",
    "         35: 'skis',\n",
    "         36: 'snowboard',\n",
    "         37: 'sports ball',\n",
    "         38: 'kite',\n",
    "         39: 'baseball bat',\n",
    "         40: 'baseball glove',\n",
    "         41: 'skateboard',\n",
    "         42: 'surfboard',\n",
    "         43: 'tennis racket',\n",
    "         44: 'bottle',\n",
    "         46: 'wine glass',\n",
    "         47: 'cup',\n",
    "         48: 'fork',\n",
    "         49: 'knife',\n",
    "         50: 'spoon',\n",
    "         51: 'bowl',\n",
    "         52: 'banana',\n",
    "         53: 'apple',\n",
    "         54: 'sandwich',\n",
    "         55: 'orange',\n",
    "         56: 'broccoli',\n",
    "         57: 'carrot',\n",
    "         58: 'hot dog',\n",
    "         59: 'pizza',\n",
    "         60: 'donut',\n",
    "         61: 'cake',\n",
    "         62: 'chair',\n",
    "         63: 'couch',\n",
    "         64: 'potted plant',\n",
    "         65: 'bed',\n",
    "         67: 'dining table',\n",
    "         70: 'toilet',\n",
    "         72: 'tv',\n",
    "         73: 'laptop',\n",
    "         74: 'mouse',\n",
    "         75: 'remote',\n",
    "         76: 'keyboard',\n",
    "         77: 'cell phone',\n",
    "         78: 'microwave',\n",
    "         79: 'oven',\n",
    "         80: 'toaster',\n",
    "         81: 'sink',\n",
    "         82: 'refrigerator',\n",
    "         84: 'book',\n",
    "         85: 'clock',\n",
    "         86: 'vase',\n",
    "         87: 'scissors',\n",
    "         88: 'teddy bear',\n",
    "         89: 'hair drier',\n",
    "         90: 'toothbrush'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T10:50:11.709940Z",
     "iopub.status.busy": "2025-08-09T10:50:11.709225Z",
     "iopub.status.idle": "2025-08-09T10:50:11.714160Z",
     "shell.execute_reply": "2025-08-09T10:50:11.713389Z",
     "shell.execute_reply.started": "2025-08-09T10:50:11.709914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Color Palatte\n",
    "R = np.array(np.arange(96, 256, 32))\n",
    "G = np.roll(R, 1)\n",
    "B = np.roll(R, 2)\n",
    "\n",
    "COLOR_IDS = np.array(np.meshgrid(R, G, B)).T.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T10:50:15.096305Z",
     "iopub.status.busy": "2025-08-09T10:50:15.095698Z",
     "iopub.status.idle": "2025-08-09T10:52:35.849672Z",
     "shell.execute_reply": "2025-08-09T10:52:35.848920Z",
     "shell.execute_reply.started": "2025-08-09T10:50:15.096282Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model:  https://tfhub.dev/tensorflow/efficientdet/d4/1\n",
      "\n",
      "model loaded!\n"
     ]
    }
   ],
   "source": [
    "EfficientDet  = {'EfficientDet D0 512x512'   : 'https://tfhub.dev/tensorflow/efficientdet/d0/1',\n",
    "                 'EfficientDet D1 640x640'   : 'https://tfhub.dev/tensorflow/efficientdet/d1/1',\n",
    "                 'EfficientDet D2 768x768'   : 'https://tfhub.dev/tensorflow/efficientdet/d2/1',\n",
    "                 'EfficientDet D3 896x896'   : 'https://tfhub.dev/tensorflow/efficientdet/d3/1',\n",
    "                 'EfficientDet D4 1024x1024' : 'https://tfhub.dev/tensorflow/efficientdet/d4/1',\n",
    "                 'EfficientDet D5 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d5/1',\n",
    "                 'EfficientDet D6 1280x1280' : 'https://tfhub.dev/tensorflow/efficientdet/d6/1',\n",
    "                 'EfficientDet D7 1536x1536' : 'https://tfhub.dev/tensorflow/efficientdet/d7/1'\n",
    "                }\n",
    "model_url = EfficientDet['EfficientDet D4 1024x1024' ]\n",
    "\n",
    "print('loading model: ', model_url)\n",
    "od_model = hub.load(model_url)\n",
    "\n",
    "print('\\nmodel loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T10:52:54.496333Z",
     "iopub.status.busy": "2025-08-09T10:52:54.495672Z",
     "iopub.status.idle": "2025-08-09T10:53:01.861487Z",
     "shell.execute_reply": "2025-08-09T10:53:01.860812Z",
     "shell.execute_reply.started": "2025-08-09T10:52:54.496286Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detection_anchor_indices\n",
      "detection_boxes\n",
      "detection_classes\n",
      "detection_multiclass_scores\n",
      "detection_scores\n",
      "num_detections\n",
      "raw_detection_boxes\n",
      "raw_detection_scores\n"
     ]
    }
   ],
   "source": [
    "model_image = load_image(sample_images[0])  # Shape (1,H,W,3)\n",
    "results = od_model(model_image)  # Pass the batched image directly\n",
    "results = {key: value.numpy() for key, value in results.items()}\n",
    "\n",
    "# Print the keys from the results dictionary\n",
    "for key in results:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T10:53:07.607429Z",
     "iopub.status.busy": "2025-08-09T10:53:07.606716Z",
     "iopub.status.idle": "2025-08-09T10:53:07.611768Z",
     "shell.execute_reply": "2025-08-09T10:53:07.611075Z",
     "shell.execute_reply.started": "2025-08-09T10:53:07.607405Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Predictions of EfficientDet 196416\n",
      "Valid Detections of EfficientDet: 100\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw Predictions of EfficientDet\",(len(results['raw_detection_scores'][0])))\n",
    "print('Valid Detections of EfficientDet:', (results['num_detections'][0]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-08-09T10:53:11.426634Z",
     "iopub.status.busy": "2025-08-09T10:53:11.426340Z",
     "iopub.status.idle": "2025-08-09T10:53:11.434766Z",
     "shell.execute_reply": "2025-08-09T10:53:11.434063Z",
     "shell.execute_reply.started": "2025-08-09T10:53:11.426612Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_dets = (results['num_detections'][0]).astype(int)\n",
    "print('\\nDetection Scores: \\n\\n', results['detection_scores'][0][0:num_dets])\n",
    "print('\\nDetection Classes: \\n\\n', results['detection_classes'][0][0:num_dets])\n",
    "print('\\nDetection Boxes: \\n\\n', results['detection_boxes'][0][0:num_dets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T11:03:15.008266Z",
     "iopub.status.busy": "2025-08-09T11:03:15.007527Z",
     "iopub.status.idle": "2025-08-09T11:03:15.020042Z",
     "shell.execute_reply": "2025-08-09T11:03:15.019329Z",
     "shell.execute_reply.started": "2025-08-09T11:03:15.008240Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_detection(image, results, min_score=0.3):\n",
    "    # Step 1: Extract the Scores, Classes, Boxes\n",
    "    scores = results['detection_scores'][0]\n",
    "    boxes = results['detection_boxes'][0]\n",
    "    classes = (results['detection_classes'][0]).astype(int)\n",
    "\n",
    "    # Filter detections by minimum score\n",
    "    filtered_indices = np.where(scores >= min_score)[0]\n",
    "    filtered_scores = scores[filtered_indices]\n",
    "    filtered_boxes = boxes[filtered_indices]\n",
    "    filtered_classes = classes[filtered_indices]\n",
    "\n",
    "    # Copy image to draw bounding boxes\n",
    "    img_bbox = image.copy()\n",
    "    image_height, image_width = image.shape[:2]\n",
    "\n",
    "    font_scale = 0.4\n",
    "    box_thickness = 2\n",
    "\n",
    "    for box, class_id, score in zip(filtered_boxes, filtered_classes, filtered_scores):\n",
    "        ymin, xmin, ymax, xmax = box\n",
    "\n",
    "        # Convert normalized box coords to pixel coords\n",
    "        left = int(xmin * image_width)\n",
    "        right = int(xmax * image_width)\n",
    "        top = int(ymin * image_height)\n",
    "        bottom = int(ymax * image_height)\n",
    "\n",
    "        class_name = class_index[class_id]  # Make sure class_index dict/list is defined\n",
    "        color = tuple(COLOR_IDS[class_id % len(COLOR_IDS)].tolist())[::-1]  # Make sure COLOR_IDS is defined\n",
    "\n",
    "        # Draw bounding box\n",
    "        img_bbox = cv2.rectangle(img_bbox, (left, top), (right, bottom), color, thickness=box_thickness)\n",
    "\n",
    "        # Prepare label text\n",
    "        display_txt = '{}: {:.2f}%'.format(class_name, 100 * score)\n",
    "\n",
    "        # Get text size for background rectangle\n",
    "        (text_width, text_height), baseline = cv2.getTextSize(display_txt, cv2.FONT_HERSHEY_SIMPLEX, font_scale, 1)\n",
    "\n",
    "        # Determine if we need to shift text down if box is too close to top\n",
    "        if top < text_height:\n",
    "            shift_down = int(2 * (1.3 * text_height))\n",
    "        else:\n",
    "            shift_down = 0\n",
    "\n",
    "        # Draw filled rectangle as background for text\n",
    "        img_bbox = cv2.rectangle(\n",
    "            img_bbox,\n",
    "            (left - 1, top - box_thickness - int(1.3 * text_height) + shift_down),\n",
    "            (left - 1 + int(1.1 * text_width), top + shift_down),\n",
    "            color,\n",
    "            thickness=-1\n",
    "        )\n",
    "\n",
    "        # Put text on top of the filled rectangle\n",
    "        img_bbox = cv2.putText(\n",
    "            img_bbox,\n",
    "            display_txt,\n",
    "            (left + int(0.05 * text_width), top - int(0.2 * text_height) + int(shift_down / 2)),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            font_scale,\n",
    "            (0, 0, 0),  # Black text color\n",
    "            1\n",
    "        )\n",
    "\n",
    "    return img_bbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T11:03:19.187895Z",
     "iopub.status.busy": "2025-08-09T11:03:19.187288Z",
     "iopub.status.idle": "2025-08-09T11:03:20.371371Z",
     "shell.execute_reply": "2025-08-09T11:03:20.370385Z",
     "shell.execute_reply.started": "2025-08-09T11:03:19.187868Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Call the model.\n",
    "results = od_model(model_image)\n",
    "\n",
    "# Convert the dictionary values to numpy arrays.\n",
    "results = {key:value.numpy() for key, value in results.items()}\n",
    "\n",
    "# Remove the batch dimension from the first image.\n",
    "image = np.squeeze(model_image,axis=0)\n",
    "\n",
    "# Process the first sample image.\n",
    "img_bbox = process_detection(image, results, min_score=0.5)\n",
    "\n",
    "plt.figure(figsize=[15, 10])\n",
    "plt.imshow(img_bbox)\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now We will Write the Code for Run Inference that Runs our model for many images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-09T11:03:30.509590Z",
     "iopub.status.busy": "2025-08-09T11:03:30.509068Z",
     "iopub.status.idle": "2025-08-09T11:03:34.954790Z",
     "shell.execute_reply": "2025-08-09T11:03:34.954079Z",
     "shell.execute_reply.started": "2025-08-09T11:03:30.509565Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def run_inference(images, model):\n",
    "    results_list = []\n",
    "    for img in images:  # img shape (1,H,W,3)\n",
    "        result = model(img)\n",
    "        result = {key: value.numpy() for key, value in result.items()}\n",
    "        results_list.append(result)\n",
    "    return results_list\n",
    "\n",
    "\n",
    "\n",
    "image_paths = images  \n",
    "\n",
    "\n",
    "sample_image_paths = random.sample(image_paths, 5)\n",
    "\n",
    "print(sample_image_paths)\n",
    "print(type(sample_image_paths[0]))\n",
    "\n",
    "\n",
    "images_loaded = [load_image(path) for path in sample_image_paths]\n",
    "\n",
    "print(type(images_loaded[0]))  \n",
    "\n",
    "\n",
    "results_list = run_inference(images_loaded, od_model)\n",
    "\n",
    "\n",
    "for idx, result in enumerate(results_list):\n",
    "    image = np.squeeze(images_loaded[idx], axis=0)  # remove batch dim\n",
    "    image_bbox = process_detection(image, result, min_score=0.31)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image_bbox)\n",
    "    plt.axis('off')\n",
    "    plt.title(os.path.basename(sample_image_paths[idx]))\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 857191,
     "sourceId": 1462296,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
